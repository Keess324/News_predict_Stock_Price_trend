{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import string\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Price_df = pd.read_csv(\"Stock_Price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Symbols</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>^GSPC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>2158.5400390625</td>\n",
       "      <td>2145.0400390625</td>\n",
       "      <td>2158.5400390625</td>\n",
       "      <td>2146.10009765625</td>\n",
       "      <td>3216170000</td>\n",
       "      <td>2146.10009765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>2161.1298828125</td>\n",
       "      <td>2141.550048828125</td>\n",
       "      <td>2146.0400390625</td>\n",
       "      <td>2159.929931640625</td>\n",
       "      <td>3437770000</td>\n",
       "      <td>2159.929931640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>2172.39990234375</td>\n",
       "      <td>2151.7900390625</td>\n",
       "      <td>2161.85009765625</td>\n",
       "      <td>2171.3701171875</td>\n",
       "      <td>3891460000</td>\n",
       "      <td>2171.3701171875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attributes              High                Low              Open  \\\n",
       "0     Symbols             ^GSPC              ^GSPC             ^GSPC   \n",
       "1        Date               NaN                NaN               NaN   \n",
       "2  2016-09-26   2158.5400390625    2145.0400390625   2158.5400390625   \n",
       "3  2016-09-27   2161.1298828125  2141.550048828125   2146.0400390625   \n",
       "4  2016-09-28  2172.39990234375    2151.7900390625  2161.85009765625   \n",
       "\n",
       "               Close      Volume          Adj Close  \n",
       "0              ^GSPC       ^GSPC              ^GSPC  \n",
       "1                NaN         NaN                NaN  \n",
       "2   2146.10009765625  3216170000   2146.10009765625  \n",
       "3  2159.929931640625  3437770000  2159.929931640625  \n",
       "4    2171.3701171875  3891460000    2171.3701171875  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stock_Price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_title</th>\n",
       "      <th>News_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>['Indian Stocks Emerge From the Crowd ', 'Dona...</td>\n",
       "      <td>['           Indian shares are on a roll in 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>['Takata Air Bags Recalled in South Korea ', '...</td>\n",
       "      <td>['           South Korea’s transport ministry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>['Photos of the Day:Asia ', 'Missile System Th...</td>\n",
       "      <td>['           A man visits the Forbidden City i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>['Photos of the Day: Asia ', 'Traders to Scour...</td>\n",
       "      <td>['           Bodybuilders compete over their m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>['Vietnam to Launch New Benchmark Stock Index ...</td>\n",
       "      <td>['           Vietnam said it will launch VNX A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                                         News_title  \\\n",
       "0           0  2016-09-26  ['Indian Stocks Emerge From the Crowd ', 'Dona...   \n",
       "1           1  2016-09-27  ['Takata Air Bags Recalled in South Korea ', '...   \n",
       "2           2  2016-09-28  ['Photos of the Day:Asia ', 'Missile System Th...   \n",
       "3           3  2016-09-29  ['Photos of the Day: Asia ', 'Traders to Scour...   \n",
       "4           4  2016-09-30  ['Vietnam to Launch New Benchmark Stock Index ...   \n",
       "\n",
       "                                       News_abstract  \n",
       "0  ['           Indian shares are on a roll in 20...  \n",
       "1  ['           South Korea’s transport ministry ...  \n",
       "2  ['           A man visits the Forbidden City i...  \n",
       "3  ['           Bodybuilders compete over their m...  \n",
       "4  ['           Vietnam said it will launch VNX A...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['Indian Stocks Emerge From the Crowd ', 'Dona...\n",
       "1    ['Takata Air Bags Recalled in South Korea ', '...\n",
       "2    ['Photos of the Day:Asia ', 'Missile System Th...\n",
       "3    ['Photos of the Day: Asia ', 'Traders to Scour...\n",
       "4    ['Vietnam to Launch New Benchmark Stock Index ...\n",
       "5    ['U.S. Auto Sales Slipped in September ', 'Nob...\n",
       "6    ['Derrick Rose’s Trial Begins as Knicks Start ...\n",
       "7    ['Oregon Standoff Leader Ammon Bundy Testifies...\n",
       "8    ['North Korea Activity at Nuclear Sites Raises...\n",
       "9    ['U.S. Carriers to Allow Second Samsung Phone ...\n",
       "Name: News_title, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['News_title'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['           Indian shares are on a roll in 20...\n",
       "1    ['           South Korea’s transport ministry ...\n",
       "2    ['           A man visits the Forbidden City i...\n",
       "3    ['           Bodybuilders compete over their m...\n",
       "4    ['           Vietnam said it will launch VNX A...\n",
       "5    ['           Light-vehicle sales sputtered in ...\n",
       "6    ['           Knicks guard Derrick Rose’s civil...\n",
       "7    ['           The leader of a 41-day standoff a...\n",
       "8    ['           Satellite images showing vehicles...\n",
       "9    ['           U.S. phone carriers said Friday t...\n",
       "Name: News_abstract, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['News_abstract'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 4)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 7)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stock_Price_df.drop(Stock_Price_df.index[:2], inplace=True)\n",
    "Stock_Price_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Mining\n",
    "##### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_filter(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(ch for ch in text if ch not in set(string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)    # remove digits\n",
    "    text = \" \".join(text.split())     # remove white space\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens1 = word_tokenize(text)\n",
    "    text1 = [i for i in tokens1 if not i in stop_words] # remove stop words\n",
    "    text1 = ' '.join(text1) # Back to string\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    tokens2 = word_tokenize(text1)\n",
    "    text2 = [lemmatizer.lemmatize(word) for word in tokens2] # lemmatizer\n",
    "#     text2 = ' '.join(text2) # Back to string\n",
    "#     stemmer= PorterStemmer()\n",
    "#     tokens3=word_tokenize(text2)\n",
    "#     text3 = [stemmer.stem(word) for word in tokens3] # stemmer\n",
    "    \n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_filter(df):\n",
    "#     cleaned_title = []\n",
    "    for index, day_news in enumerate(df['News_title']):\n",
    "        day_news = day_news[1:-1]\n",
    "        filter_day_news = news_filter(day_news)\n",
    "        news_df['News_title'][index] = \" \".join(filter_day_news)\n",
    "    for index, day_abs in enumerate(df['News_abstract']):\n",
    "        day_abs = day_abs[1:-1]\n",
    "        filter_day_abs = news_filter(day_abs)\n",
    "        news_df['News_abstract'][index] = \" \".join(filter_day_abs)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "raw_to_filter(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_title</th>\n",
       "      <th>News_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>indian stock emerge crowd donald trump attack ...</td>\n",
       "      <td>indian share roll many investor say country be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>takata air bag recalled south korea ペレス前イスラエル大...</td>\n",
       "      <td>south korea ’ transport ministry ordered dozen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>photo dayasia missile system downed mh said ru...</td>\n",
       "      <td>man visit forbidden city beijing hindu devotee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>photo day asia trader scour japan ’ bondbuying...</td>\n",
       "      <td>bodybuilder compete muscle championship nepal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>vietnam launch new benchmark stock index orego...</td>\n",
       "      <td>vietnam said launch vnx allshare oct include s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>u auto sale slipped september nobel prize medi...</td>\n",
       "      <td>lightvehicle sale sputtered u last month despi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>derrick rose ’ trial begin knicks start presea...</td>\n",
       "      <td>knicks guard derrick rose ’ civil trial regard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>oregon standoff leader ammon bundy testifies t...</td>\n",
       "      <td>leader day standoff national wildlife refuge o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>north korea activity nuclear site raise specul...</td>\n",
       "      <td>satellite image showing vehicle people around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>u carrier allow second samsung phone replaceme...</td>\n",
       "      <td>u phone carrier said friday allowing customer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                                         News_title  \\\n",
       "0           0  2016-09-26  indian stock emerge crowd donald trump attack ...   \n",
       "1           1  2016-09-27  takata air bag recalled south korea ペレス前イスラエル大...   \n",
       "2           2  2016-09-28  photo dayasia missile system downed mh said ru...   \n",
       "3           3  2016-09-29  photo day asia trader scour japan ’ bondbuying...   \n",
       "4           4  2016-09-30  vietnam launch new benchmark stock index orego...   \n",
       "5           5  2016-10-03  u auto sale slipped september nobel prize medi...   \n",
       "6           6  2016-10-04  derrick rose ’ trial begin knicks start presea...   \n",
       "7           7  2016-10-05  oregon standoff leader ammon bundy testifies t...   \n",
       "8           8  2016-10-06  north korea activity nuclear site raise specul...   \n",
       "9           9  2016-10-07  u carrier allow second samsung phone replaceme...   \n",
       "\n",
       "                                       News_abstract  \n",
       "0  indian share roll many investor say country be...  \n",
       "1  south korea ’ transport ministry ordered dozen...  \n",
       "2  man visit forbidden city beijing hindu devotee...  \n",
       "3  bodybuilder compete muscle championship nepal ...  \n",
       "4  vietnam said launch vnx allshare oct include s...  \n",
       "5  lightvehicle sale sputtered u last month despi...  \n",
       "6  knicks guard derrick rose ’ civil trial regard...  \n",
       "7  leader day standoff national wildlife refuge o...  \n",
       "8  satellite image showing vehicle people around ...  \n",
       "9  u phone carrier said friday allowing customer ...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out to .csv for future steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv(\"newscleaned1_kc3214.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of collected daily news:  508\n",
      "Number of collected daily stock price: 508\n"
     ]
    }
   ],
   "source": [
    "print(\"Numbers of collected daily news: \", news_df.shape[0])\n",
    "print(\"Number of collected daily stock price:\", Stock_Price_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"newscleaned1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the first round Text Mining did not delete all useless information<br> \n",
    "so we are tying to go further on text mining steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Words frequency, and create a high frequency set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaron', 'ab', 'abandon', 'abandoned', 'abandoning', 'abb', 'abbas', 'abbott', 'abbvie', 'abc', 'abe', 'abercrombie', 'ability', 'able', 'aboard', 'abode', 'abortion', 'abraaj', 'abroad', 'absence', 'absolute', 'absolutely', 'absorb', 'abu', 'abuse', 'abusive', 'ac', 'aca', 'academic', 'academy', 'accelerate', 'accelerated', 'accelerates', 'accelerating', 'accenture', 'accept', 'acceptance', 'accepts', 'access', 'accessible', 'accessory', 'accident', 'accidental', 'accord', 'according', 'account', 'accountability', 'accountable', 'accountant', 'accounting', 'accusation', 'accuse', 'accused', 'accuser', 'accuses', 'ace', 'achievement', 'ackman', 'acknowledges', 'aclu', 'acosta', 'acquire', 'acquired', 'acquires', 'acquiring', 'acquisition', 'acquitted', 'act', 'acted', 'actelion', 'acting', 'action', 'active', 'activision', 'activism', 'activist', 'activity', 'actor', 'actress', 'actual', 'actually', 'ad', 'adam', 'adapt', 'adapts', 'add', 'added', 'addict', 'addicted', 'addiction', 'adding', 'addition', 'additional', 'addon', 'address', 'adelson', 'adidas', 'adjust', 'adjustment', 'adm']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoning</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abb</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbas</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbott</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbvie</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abercrombie</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abode</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abraaj</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abroad</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absence</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorb</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abu</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abusive</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aca</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academic</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academy</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yogurt</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>york</th>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorkarea</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorker</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorkers</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>younger</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuan</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zambia</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zara</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zell</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zenefits</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zika</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zimbabwe</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinc</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinke</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zion</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zodiac</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zohar</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zte</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuma</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>写真で見る世界のニュース</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              frequency\n",
       "aaron                16\n",
       "ab                   17\n",
       "abandon              18\n",
       "abandoned             9\n",
       "abandoning            5\n",
       "abb                   7\n",
       "abbas                 7\n",
       "abbott               10\n",
       "abbvie                7\n",
       "abc                  18\n",
       "abe                  42\n",
       "abercrombie          11\n",
       "ability              18\n",
       "able                 12\n",
       "aboard                9\n",
       "abode                 7\n",
       "abortion             41\n",
       "abraaj               23\n",
       "abroad               34\n",
       "absence              10\n",
       "absolute              5\n",
       "absolutely            6\n",
       "absorb                5\n",
       "abu                  13\n",
       "abuse               109\n",
       "abusive               7\n",
       "ac                    5\n",
       "aca                  58\n",
       "academic             32\n",
       "academy              19\n",
       "...                 ...\n",
       "yogurt               10\n",
       "york               1012\n",
       "yorkarea              6\n",
       "yorker                6\n",
       "yorkers              28\n",
       "young               101\n",
       "younger              11\n",
       "youth                16\n",
       "youtube              70\n",
       "yuan                 80\n",
       "yum                   9\n",
       "zambia                5\n",
       "zara                 15\n",
       "zealand              31\n",
       "zell                  5\n",
       "zenefits              8\n",
       "zero                 24\n",
       "zika                 24\n",
       "zimbabwe             27\n",
       "zinc                  5\n",
       "zinke                 6\n",
       "zion                  5\n",
       "zodiac                5\n",
       "zohar                 8\n",
       "zombie                9\n",
       "zone                 30\n",
       "zte                  41\n",
       "zuckerberg           38\n",
       "zuma                 18\n",
       "写真で見る世界のニュース          5\n",
       "\n",
       "[8181 rows x 1 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For News Title\n",
    "word_vectorizer_tit = CountVectorizer(analyzer='word', stop_words='english', min_df=5)\n",
    "Smatrix = word_vectorizer_tit.fit_transform(news_df['News_title'])\n",
    "frequencies = sum(Smatrix).toarray()[0]\n",
    "freq_names = word_vectorizer_tit.get_feature_names()\n",
    "print(freq_names[:100])\n",
    "freq = pd.DataFrame(frequencies, index = freq_names, columns=['frequency'])\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaron', 'ab', 'abandon', 'abandoned', 'abandoning', 'abated', 'abating', 'abb', 'abbas', 'abbey', 'abbott', 'abbvie', 'abc', 'abdel', 'abducted', 'abduction', 'abdul', 'abdussalaam', 'abe', 'abercrombie', 'aberdeen', 'abide', 'abigail', 'ability', 'able', 'abnormal', 'aboard', 'abolish', 'aborted', 'abortion', 'abound', 'aboutface', 'abraaj', 'abraham', 'abrams', 'abroad', 'abrupt', 'abruptly', 'absence', 'absent', 'absolute', 'absolutely', 'absorb', 'absorbed', 'abstract', 'absurd', 'abu', 'abundance', 'abundant', 'abuse', 'abused', 'abuser', 'abusing', 'abusive', 'aca', 'academia', 'academic', 'academy', 'accelerate', 'accelerated', 'accelerates', 'accelerating', 'acceleration', 'accelerator', 'accent', 'accenture', 'accept', 'acceptable', 'acceptance', 'accepted', 'accepting', 'accepts', 'access', 'accessed', 'accessible', 'accession', 'accessory', 'accident', 'accidental', 'accidentally', 'acclaimed', 'accolade', 'accommodate', 'accommodation', 'accommodative', 'accompanied', 'accompanying', 'accomplice', 'accomplish', 'accomplished', 'accomplishment', 'accord', 'according', 'account', 'accountability', 'accountable', 'accountant', 'accounted', 'accounting', 'accreditation']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoning</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abated</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abating</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abb</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbas</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbey</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbott</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbvie</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdel</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abducted</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abduction</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdul</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdussalaam</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abercrombie</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberdeen</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abigail</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abolish</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aborted</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zen</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zenefits</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeroing</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zerotolerance</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zesty</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhang</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhejiang</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zika</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zimbabwe</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zimmer</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinc</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinke</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zodiac</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zohar</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoning</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zte</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuma</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurich</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zweig</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynga</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>½year</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>álvaro</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               frequency\n",
       "aaron                 29\n",
       "ab                    15\n",
       "abandon               46\n",
       "abandoned             56\n",
       "abandoning            37\n",
       "abated                 8\n",
       "abating                6\n",
       "abb                    6\n",
       "abbas                 12\n",
       "abbey                  5\n",
       "abbott                27\n",
       "abbvie                10\n",
       "abc                   29\n",
       "abdel                 22\n",
       "abducted              10\n",
       "abduction              6\n",
       "abdul                  6\n",
       "abdussalaam            6\n",
       "abe                   74\n",
       "abercrombie           10\n",
       "aberdeen               5\n",
       "abide                 10\n",
       "abigail                7\n",
       "ability              264\n",
       "able                 181\n",
       "abnormal               6\n",
       "aboard                25\n",
       "abolish               14\n",
       "aborted                8\n",
       "abortion              62\n",
       "...                  ...\n",
       "zen                    7\n",
       "zenefits               7\n",
       "zero                  70\n",
       "zeroing                9\n",
       "zerotolerance          5\n",
       "zesty                  5\n",
       "zhang                  8\n",
       "zhejiang               6\n",
       "zika                  24\n",
       "zimbabwe              29\n",
       "zimmer                41\n",
       "zinc                   9\n",
       "zinke                 15\n",
       "zip                    5\n",
       "zodiac                 9\n",
       "zohar                  7\n",
       "zombie                 8\n",
       "zone                  64\n",
       "zoning                12\n",
       "zoo                    6\n",
       "zoom                   6\n",
       "zte                   47\n",
       "zucchini               5\n",
       "zuckerberg            46\n",
       "zuma                  24\n",
       "zurich                 5\n",
       "zweig                  6\n",
       "zynga                  5\n",
       "½year                  8\n",
       "álvaro                 6\n",
       "\n",
       "[15501 rows x 1 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For News Abstract\n",
    "word_vectorizer_abs = CountVectorizer(analyzer='word', stop_words='english', min_df=5)\n",
    "Smatrix_abs = word_vectorizer_abs.fit_transform(news_df['News_abstract'])\n",
    "frequencies_abs = sum(Smatrix_abs).toarray()[0]\n",
    "freq_names_abs = word_vectorizer_abs.get_feature_names()\n",
    "print(freq_names_abs[:100])\n",
    "freq = pd.DataFrame(frequencies_abs, index = freq_names_abs, columns=['frequency'])\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the words frequency < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_word_news = set(freq_names)\n",
    "high_freq_word_abs = set(freq_names_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delet_low_fre(df, high_freq_word_news, high_freq_word_abs):\n",
    "    for index, day_news in  enumerate(df['News_title']):\n",
    "        news_df['News_title'][index] = \" \".join( set(day_news.split()) - (set(day_news.split()) - high_freq_word_news))\n",
    "        \n",
    "    for index, day_abs in  enumerate (df['News_abstract']):\n",
    "        news_df['News_abstract'][index] = \" \".join( set(day_abs.split()) - (set(day_abs.split()) - high_freq_word_abs))\n",
    "        \n",
    "    return news_df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "news_df = delet_low_fre(news_df, high_freq_word_news, high_freq_word_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News_title</th>\n",
       "      <th>News_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>additional skyhigh peres loss export lineup cr...</td>\n",
       "      <td>bare rescind prevent chemical include accompan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>blunt restoration peres loss wealth list fisch...</td>\n",
       "      <td>version oppose loss export according list food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>better lyft chemical peres loss knew robert li...</td>\n",
       "      <td>assuming chemical theatre loss export conducte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>viral peres loss sound list credit pass rip la...</td>\n",
       "      <td>spurring mishandled export according transpare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>peres loss reviewing list robert stance charlo...</td>\n",
       "      <td>fled version blunt persisted include peres los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>better bone slipped loss empire wealth path so...</td>\n",
       "      <td>bone prevent slipped chemical loss empire acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>viking loss va list food los obamacare erdogan...</td>\n",
       "      <td>prevent hightech viking loss stretch conducted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>chemical peres reduce reviewing credit currenc...</td>\n",
       "      <td>version mishandled theatre floundering loss ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>better additional william guest siri direct le...</td>\n",
       "      <td>version guest prevent slipped oppose include l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>better chemical escape empire stance fischer c...</td>\n",
       "      <td>rural flash rushing prop slipped chemical incl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                         News_title  \\\n",
       "0  2016-09-26  additional skyhigh peres loss export lineup cr...   \n",
       "1  2016-09-27  blunt restoration peres loss wealth list fisch...   \n",
       "2  2016-09-28  better lyft chemical peres loss knew robert li...   \n",
       "3  2016-09-29  viral peres loss sound list credit pass rip la...   \n",
       "4  2016-09-30  peres loss reviewing list robert stance charlo...   \n",
       "5  2016-10-03  better bone slipped loss empire wealth path so...   \n",
       "6  2016-10-04  viking loss va list food los obamacare erdogan...   \n",
       "7  2016-10-05  chemical peres reduce reviewing credit currenc...   \n",
       "8  2016-10-06  better additional william guest siri direct le...   \n",
       "9  2016-10-07  better chemical escape empire stance fischer c...   \n",
       "\n",
       "                                       News_abstract  \n",
       "0  bare rescind prevent chemical include accompan...  \n",
       "1  version oppose loss export according list food...  \n",
       "2  assuming chemical theatre loss export conducte...  \n",
       "3  spurring mishandled export according transpare...  \n",
       "4  fled version blunt persisted include peres los...  \n",
       "5  bone prevent slipped chemical loss empire acco...  \n",
       "6  prevent hightech viking loss stretch conducted...  \n",
       "7  version mishandled theatre floundering loss ex...  \n",
       "8  version guest prevent slipped oppose include l...  \n",
       "9  rural flash rushing prop slipped chemical incl...  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv(\"newscleaned2_kc3214.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
